{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867c17b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have tensorflow 2.19.1 and this requires tf-keras package. Please run `pip install tf-keras` or downgrade your tensorflow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\Interview-Coach-AI-Communication-Confidence-Analyzer\\venv\\lib\\site-packages\\retinaface\\commons\\package_utils.py:19\u001b[0m, in \u001b[0;36mvalidate_for_keras3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras is already available - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_keras\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[0;32m      5\u001b[0m mp_face \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mface_detection\n\u001b[0;32m      6\u001b[0m mp_draw \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n",
      "File \u001b[1;32md:\\Interview-Coach-AI-Communication-Confidence-Analyzer\\venv\\lib\\site-packages\\deepface\\DeepFace.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m package_utils, folder_utils\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     modeling,\n\u001b[0;32m     22\u001b[0m     representation,\n\u001b[0;32m     23\u001b[0m     verification,\n\u001b[0;32m     24\u001b[0m     recognition,\n\u001b[0;32m     25\u001b[0m     demography,\n\u001b[0;32m     26\u001b[0m     detection,\n\u001b[0;32m     27\u001b[0m     streaming,\n\u001b[0;32m     28\u001b[0m     preprocessing,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger()\n",
      "File \u001b[1;32md:\\Interview-Coach-AI-Communication-Confidence-Analyzer\\venv\\lib\\site-packages\\deepface\\modules\\modeling.py:17\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfacial_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     VGGFace,\n\u001b[0;32m      7\u001b[0m     OpenFace,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     Buffalo_L\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mface_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     FastMtCnn,\n\u001b[0;32m     19\u001b[0m     MediaPipe,\n\u001b[0;32m     20\u001b[0m     MtCnn,\n\u001b[0;32m     21\u001b[0m     OpenCv,\n\u001b[0;32m     22\u001b[0m     Dlib \u001b[38;5;28;01mas\u001b[39;00m DlibDetector,\n\u001b[0;32m     23\u001b[0m     RetinaFace,\n\u001b[0;32m     24\u001b[0m     Ssd,\n\u001b[0;32m     25\u001b[0m     Yolo \u001b[38;5;28;01mas\u001b[39;00m YoloFaceDetector,\n\u001b[0;32m     26\u001b[0m     YuNet,\n\u001b[0;32m     27\u001b[0m     CenterFace,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdemography\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Age, Gender, Race, Emotion\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspoofing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FasNet\n",
      "File \u001b[1;32md:\\Interview-Coach-AI-Communication-Confidence-Analyzer\\venv\\lib\\site-packages\\deepface\\models\\face_detection\\RetinaFace.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 3rd party dependencies\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mretinaface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetinaFace \u001b[38;5;28;01mas\u001b[39;00m rf\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDetector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Detector, FacialAreaRegion\n",
      "File \u001b[1;32md:\\Interview-Coach-AI-Communication-Confidence-Analyzer\\venv\\lib\\site-packages\\retinaface\\RetinaFace.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mretinaface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m package_utils\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# users should install tf_keras package if they are using tf 2.16 or later versions\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mpackage_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_for_keras3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretinaface/RetinaFace.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=global-variable-undefined, no-name-in-module, unused-import, too-many-locals, redefined-outer-name, too-many-statements, too-many-arguments\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# configurations\u001b[39;00m\n",
      "File \u001b[1;32md:\\Interview-Coach-AI-Communication-Confidence-Analyzer\\venv\\lib\\site-packages\\retinaface\\commons\\package_utils.py:24\u001b[0m, in \u001b[0;36mvalidate_for_keras3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras is already available - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_keras\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# you may consider to install that package here\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have tensorflow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and this requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf-keras package. Please run `pip install tf-keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor downgrade your tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: You have tensorflow 2.19.1 and this requires tf-keras package. Please run `pip install tf-keras` or downgrade your tensorflow."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from deepface import DeepFace\n",
    "\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(rgb)\n",
    "        if results.detections:\n",
    "            for det in results.detections:\n",
    "                box = det.location_data.relative_bounding_box\n",
    "                h, w, _ = frame.shape\n",
    "                x, y, w_box, h_box = int(box.xmin*w), int(box.ymin*h), int(box.width*w), int(box.height*h)\n",
    "                face = frame[y:y+h_box, x:x+w_box]\n",
    "                if face.size > 0:\n",
    "                    res = DeepFace.analyze(face, actions=['emotion'], enforce_detection=False)\n",
    "                    emotion = res[0]['dominant_emotion']\n",
    "                    cv2.rectangle(frame, (x, y), (x+w_box, y+h_box), (0,255,0), 2)\n",
    "                    cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "        cv2.imshow(\"Mediapipe + DeepFace Emotion Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
